{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage import transform,feature,exposure\n",
    "import pickle\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readTrafficSigns(rootpath):\n",
    "    images = [] # images\n",
    "    labels = [] # corresponding labels\n",
    "    for c in range(0,43):\n",
    "        prefix = rootpath + '/' + format(c, '05d') + '/' # subdirectory for class\n",
    "        gtFile = open(prefix + 'GT-'+ format(c, '05d') + '.csv') # annotations file\n",
    "        gtReader = csv.reader(gtFile, delimiter=';') # csv parser for annotations file\n",
    "        gtReader.next() # skip header\n",
    "        for row in gtReader:\n",
    "            images.append(plt.imread(prefix + row[0])) # the 1th column is the filename\n",
    "            labels.append(row[7]) # the 8th column is the label\n",
    "        gtFile.close()\n",
    "    return images, labels\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "\n",
    "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "    return gray\n",
    "\n",
    "\n",
    "def showimg_n_hog(grayimg,hogImage):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 10), sharex=True, sharey=True)\n",
    "    ax1.axis('off')\n",
    "    ax1.imshow(grayimg)\n",
    "    ax1.set_title('Input image')\n",
    "    ax1.set_adjustable('box-forced')\n",
    "\n",
    "    ax2.axis('off')\n",
    "    ax2.imshow(hogImage, cmap=plt.cm.gray)\n",
    "    ax2.set_title('Histogram of Oriented Gradients')\n",
    "    ax1.set_adjustable('box-forced')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def get_csv(path):\n",
    "    return [os.path.join(path,f) for f in os.listdir(path) if f.endswith('.csv')]\n",
    "\n",
    "def loadtestimages_from_path(testpath):\n",
    "    print(\"[INFO] reading all test images from directory\\n\")\n",
    "    filename = testpath+\"/new.csv\"\n",
    "    raw_data = open(filename, 'rt')\n",
    "    reader = csv.reader(raw_data, delimiter=';')\n",
    "    reader.next()\n",
    "    testfiles = list(reader)\n",
    "    timg = []\n",
    "    testimg = []\n",
    "    for row in testfiles:\n",
    "        fname = os.path.join(testpath,row[0])\n",
    "        timg.append(fname)\n",
    "        testimg.append(plt.imread(fname))\n",
    "    return timg,testimg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Code : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Train Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training images and labels are loaded in variables ==> X,y\n",
      "[INFO] Number of training Images 39209 \n",
      "Number of Labels 39209\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(\"Image_n_Labels/trainImages.npy\") &  os.path.isfile(\"Image_n_Labels/trainLabels.npy\") :\n",
    "    X = np.load(\"Image_n_Labels/trainImages.npy\")\n",
    "    y = np.load(\"Image_n_Labels/trainLabels.npy\")\n",
    "    print(\"[INFO] Training images and labels are loaded in variables ==> X,y\")\n",
    "    print(\"[INFO] Number of training Images {} \\nNumber of Labels {}\".format(len(X), len(y)))\n",
    "    \n",
    "else:\n",
    "    trainImages, trainLabels =readTrafficSigns(\"/home/rupali/Desktop/project/GTSRB/dataset/GTSRB/Final_Training/Images\")\n",
    "    np.save(\"Image_n_Labels/trainImages.npy\",trainImages)\n",
    "    np.save(\"Image_n_Labels/trainLabels.npy\",trainLabels)\n",
    "    print(\"[INFO] training images and labels are read from the dataset directory\")\n",
    "    print(\"[INFO] training images saved to Image_n_Labels/trainingImages.npy for further use\")\n",
    "    print(\"[INFO] training labels saved to Image_n_Labels/trainingLabels.npy for further use\")\n",
    "    X = np.load(\"Image_n_Labels/trainImages.npy\")\n",
    "    y = np.load(\"Image_n_Labels/trainLabels.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading from .npy\n",
      "\n",
      "[INFO] DONE!loaded from .npy\n",
      "\n",
      "[INFO] Training images and labels are loaded in variables ==> X,y\n",
      "[INFO] Number of training Images 12630 \n",
      "Number of Labels 12630\n"
     ]
    }
   ],
   "source": [
    "if (os.path.isfile(\"Image_n_Labels/testimagenames.npy\") &  os.path.isfile(\"Image_n_Labels/testimages.npy\")):\n",
    "    print(\"[INFO] loading from .npy\\n\")\n",
    "    timg = np.load(\"Image_n_Labels/testimagenames.npy\")\n",
    "    testimg = np.load(\"Image_n_Labels/testimages.npy\")\n",
    "    print(\"[INFO] DONE!loaded from .npy\\n\")\n",
    "    print(\"[INFO] Training images and labels are loaded in variables ==> X,y\")\n",
    "    print(\"[INFO] Number of training Images {} \\nNumber of Labels {}\".format(len(timg), len(testimg)))\n",
    "else:\n",
    "    testpath=\"/home/rupali/Desktop/project/GTSRB/dataset/GTSRB_test/Final_Test/small\"\n",
    "    timg,testimg = loadtestimages_from_path(testpath)\n",
    "    np.save(\"Image_n_Labels/testimagenames.npy\",timg)\n",
    "    np.save(\"Image_n_Labels/testimages.npy\",testimg)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract HoG features over all training images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading from file ... \n",
      "HoG features are loaded from HoGfeatures.npy to variable ==> hogfeat\n",
      "HoG visualizations are loaded from HoGvisualize.npy to variable ==> hogviz\n",
      "(39209, 2916)\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(\"HoGFeatures/HoGfeatures.npy\") & os.path.isfile(\"HoGFeatures/HoGvisualize.npy\") :\n",
    "    print(\"[INFO] loading from file ... \")\n",
    "    hogfeat = np.load(\"HoGFeatures/HoGfeatures.npy\")\n",
    "    hogviz = np.load(\"HoGFeatures/HoGvisualize.npy\")\n",
    "    \n",
    "    print(\"HoG features are loaded from HoGfeatures.npy to variable ==> hogfeat\")\n",
    "    print(\"HoG visualizations are loaded from HoGvisualize.npy to variable ==> hogviz\")\n",
    "    \n",
    "else:\n",
    "    Hviz=[]\n",
    "    Hfeat=[]\n",
    "    print(\"[INFO] HoGfeatures.npy does not exist\")\n",
    "    for i in range(len(X)):\n",
    "        if i > 0 and i % 1000 == 0:\n",
    "            print(\"[INFO] processed {}/{}\".format(i, len(X)))\n",
    "        i1 = X[i]\n",
    "        grayim = rgb2gray(i1)\n",
    "        gI1 = transform.resize(grayim,(40,40))\n",
    "        (H, hogImage) = feature.hog(gI1, orientations=9, pixels_per_cell=(4,4),cells_per_block=(2, 2), transform_sqrt=True, visualise=True)\n",
    "        hogImage = exposure.rescale_intensity(hogImage, out_range=(0, 255)).astype(\"uint8\")\n",
    "\n",
    "        Hviz.append(hogImage)\n",
    "        Hfeat.append(H)\n",
    "\n",
    "    np.save(\"HoGFeatures/HoGfeatures.npy\", Hfeat)\n",
    "    np.save(\"HoGFeatures/HoGvisualize.npy\", Hviz)\n",
    "    print(\"[INFO] HoGfeatures.npy are saved\")  \n",
    "    print(\"[INFO] HoGvisualize.npy are saved\")\n",
    "    hogfeat = np.load(\"HoGFeatures/HoGfeatures.npy\")\n",
    "    hogviz = np.load(\"HoGFeatures/HoGvisualize.npy\")\n",
    "print (hogfeat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract HoG features over all Testing images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HoG features are loaded from HoGfeatures_test.npy to variable ==> hogfeat_test\n",
      "HoG visualizations are loaded from HoGvisualize_test.npy to variable ==> hogviz_test\n",
      "(12630, 2916)\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(\"HoGFeatures/HoGfeatures_test.npy\") & os.path.isfile(\"HoGFeatures/HoGvisualize_test.npy\") :\n",
    "    hogfeat_test = np.load(\"HoGFeatures/HoGfeatures_test.npy\")\n",
    "    hogviz_test = np.load(\"HoGFeatures/HoGvisualize_test.npy\")\n",
    "    \n",
    "    print(\"HoG features are loaded from HoGfeatures_test.npy to variable ==> hogfeat_test\")\n",
    "    print(\"HoG visualizations are loaded from HoGvisualize_test.npy to variable ==> hogviz_test\")\n",
    "else:\n",
    "    print(\"HoGfeatures_test.npy does not found\")\n",
    "    Hviz = []\n",
    "    Hfeat = []\n",
    "    for i in range(0,len(testimg)):\n",
    "        # show an update every 1,000 images\n",
    "        if i > 0 and i % 10 == 0:\n",
    "            print(\"[INFO] processed {}/{}\".format(i, len(testimg)))\n",
    "        I = testimg[i]\n",
    "        grayim = rgb2gray(I)\n",
    "        grayim = transform.resize(grayim,(40,40))\n",
    "\n",
    "        (H_4x4, hogImage) = feature.hog(grayim, orientations=9, pixels_per_cell=(4, 4),\n",
    "            cells_per_block=(2, 2), transform_sqrt=True, visualise=True)\n",
    "        hogImage = exposure.rescale_intensity(hogImage, out_range=(0, 255)).astype(\"uint8\")\n",
    "        Hviz.append(hogImage)\n",
    "        Hfeat.append(H_4x4)\n",
    "        # save the features using numpy save with .npy extention \n",
    "        # which reduced the storage space by 4times compared to pickle\n",
    "    np.save(\"HoGFeatures/HoGfeatures_test.npy\", Hfeat)\n",
    "    np.save(\"HoGFeatures/HoGvisualize_test.npy\", Hviz)\n",
    "    print(\"HoGfeatures_test.npy are saved\")  \n",
    "    print(\"HoGvisualize_test.npy are saved\")\n",
    "    hogfeat_test = np.load(\"HoGFeatures/HoGfeatures_test.npy\")\n",
    "    hogviz_test = np.load(\"HoGFeatures/HoGvisualize_test.npy\")\n",
    "print (hogfeat_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train and test dataset fromm training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data points: 26465\n",
      "validation data points: 2941\n",
      "testing data points: 9803\n"
     ]
    }
   ],
   "source": [
    "Xhog = np.array(hogfeat).astype(\"float\")\n",
    "y = y.astype(\"float\")\n",
    "X_t = np.array(hogfeat_test).astype(\"float\")\n",
    "\n",
    "\n",
    "features = Xhog\n",
    "labels = y\n",
    "Xtest = X_t\n",
    "\n",
    "# take the  data and construct the training and testing split, using 75% of the\n",
    "# data for training and 25% for testing\n",
    "(trainData, testData, trainLabels, testLabels) = train_test_split(features,\n",
    "    labels, test_size=0.25, random_state=42)\n",
    " \n",
    "# now, let's take 10% of the training data and use that for validation\n",
    "(trainData, valData, trainLabels, valLabels) = train_test_split(trainData, trainLabels,\n",
    "    test_size=0.1, random_state=84)\n",
    " \n",
    "# show the sizes of each data split\n",
    "print(\"training data points: {}\".format(len(trainLabels)))\n",
    "print(\"validation data points: {}\".format(len(valLabels)))\n",
    "print(\"testing data points: {}\".format(len(testLabels)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading classifier: Random Forest trained on HoG features...\n",
      "[INFO] Classifer is loaded as instance ::svc::\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(\"clf/clf_rf_hog.pkl\"):\n",
    "    print(\"[INFO] loading classifier: Random Forest trained on HoG features...\")\n",
    "    rf = joblib.load(\"clf/clf_rf_hog.pkl\")\n",
    "    print(\"[INFO] Classifer is loaded as instance ::svc::\")\n",
    "else:\n",
    "    print(\"[INFO] pre-trained classifier not found. \\n Training Classifier Random Forest\")\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(trainData,trainLabels)\n",
    "    print(\"[INFO] Succefully trained the classsifier. \\n Saving the classifier for further use\")\n",
    "    joblib.dump(rf, 'clf/clf_rf_hog.pkl') \n",
    "    rf = joblib.load(\"clf/clf_rf_hog.pkl\")\n",
    "    print(\"[INFO] Classifier Saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training data: 0.999395427924\n",
      "accuracy on test data: 0.884627154953\n",
      "accuracy on validation data: 0.877932675961\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy on training data: {}\".format(rf.score(trainData,trainLabels)))\n",
    "\n",
    "print(\"accuracy on test data: {}\".format(rf.score(testData,testLabels)))\n",
    "\n",
    "print(\"accuracy on validation data: {}\".format(rf.score(valData,valLabels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_score = cross_val_score(rf,testData,testLabels,cv=5)\n",
    "print(\"mean cross-validation score: {}\".format(np.mean(cv_score)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = rf.predict(testData)\n",
    " \n",
    "# show a final classification report demonstrating the accuracy of the classifier\n",
    "print(\"EVALUATION ON TESTING DATA\")\n",
    "print(classification_report(testLabels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
